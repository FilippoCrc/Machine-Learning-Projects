{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_folder = './train'\n",
    "test_folder ='./test'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_folder, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_folder, transform=transform)\n",
    "\n",
    "# Crea DataLoader per 'train' e 'test'\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN_1(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 24 * 24, 100)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, num_classes)\n",
    "        self.drop= nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.pool1(self.relu1(self.bn1((self.conv1(x)))))\n",
    "        x = self.pool2(self.relu2((self.bn2(self.conv2(x)))))\n",
    "\n",
    "        # Flatten for fully connected layers\n",
    "        x = x.reshape(-1, 32 * 24 * 24)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.drop(self.relu3(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Initialize your model\n",
    "model = CustomCNN_1()\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#print(device)\n",
    "cnn = CustomCNN_1().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(net, Loader, device):\n",
    "  acc = torchmetrics.Accuracy(task = \"multiclass\", num_classes= 5).to(device)\n",
    "  for xb, yb in train_loader:\n",
    "      xb, yb = xb.to(device), yb.to(device)\n",
    "      ypred = net(xb)\n",
    "      _ = acc(ypred, yb)\n",
    "  return acc.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_classes=5\n",
    "accuracy(cnn, train_loader, device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(cnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at epoch 0: 0.3002041280269623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:36<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at epoch 1: 0.29910504817962646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:38<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at epoch 2: 0.299576073884964\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "  \n",
    "  cnn.train()\n",
    "  for xb, yb in tqdm.tqdm(train_loader):\n",
    "    \n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    ypred = cnn(xb)\n",
    "    l = loss(ypred, yb)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  cnn.eval()\n",
    "  print(f'Accuracy at epoch {epoch}: {accuracy(cnn, test_loader, device)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
